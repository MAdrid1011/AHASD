# AHASD Reproducibility Guide

æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„æ­¥éª¤æ¥é‡ç°è®ºæ–‡ä¸­çš„å®éªŒç»“æœã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

### ç¡¬ä»¶è¦æ±‚

- **CPU**: 16+ æ ¸å¿ƒ (æ¨è Intel Xeon æˆ– AMD EPYC)
- **å†…å­˜**: 64GB+ RAM
- **å­˜å‚¨**: 500GB+ å¯ç”¨ç©ºé—´ (ç”¨äºæ¨¡æ‹Ÿå™¨è¾“å‡º)
- **å¯é€‰**: NVIDIA GPU (ç”¨äº GPU baseline å¯¹æ¯”)

### è½¯ä»¶è¦æ±‚

```bash
# æ“ä½œç³»ç»Ÿ
Ubuntu 20.04 LTS æˆ–æ›´é«˜ç‰ˆæœ¬

# ç¼–è¯‘å·¥å…·
sudo apt-get update
sudo apt-get install -y build-essential cmake ninja-build
sudo apt-get install -y gcc-10 g++-10
sudo apt-get install -y python3 python3-pip

# Chisel/Scala (ç”¨äº XiangShan)
sudo apt-get install -y default-jdk scala
curl -L https://github.com/com-lihaoyi/mill/releases/download/0.10.0/0.10.0 > mill
chmod +x mill
sudo mv mill /usr/local/bin/

# Python ä¾èµ–
pip3 install numpy matplotlib pandas jupyter
pip3 install onnx onnxruntime torch
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### æ­¥éª¤ 1: å…‹éš†ä»“åº“å¹¶åˆå§‹åŒ–å­æ¨¡å—

```bash
git clone https://github.com/your-org/AHASD.git
cd AHASD

# åˆå§‹åŒ–å­æ¨¡å— (ONNXim, PIMSimulator, XiangShan)
git submodule update --init --recursive
```

### æ­¥éª¤ 2: æ„å»º ONNXim æ¨¡æ‹Ÿå™¨

```bash
cd ONNXim

# å®‰è£… Conan ä¾èµ–ç®¡ç†å™¨
pip3 install conan

# åˆ›å»ºæ„å»ºç›®å½•
mkdir build && cd build

# é…ç½® CMake (å¯ç”¨ AHASD æ”¯æŒ)
cmake .. -G Ninja \
    -DCMAKE_BUILD_TYPE=Release \
    -DENABLE_AHASD=ON \
    -DCMAKE_CXX_COMPILER=g++-10 \
    -DCMAKE_C_COMPILER=gcc-10

# æ„å»º (è¿™å¯èƒ½éœ€è¦ 10-20 åˆ†é’Ÿ)
ninja -j$(nproc)

# éªŒè¯æ„å»º
./onnxim_main --version
# åº”è¾“å‡º: ONNXim v1.0 (AHASD enabled)

cd ../..
```

### æ­¥éª¤ 3: æ„å»º PIMSimulator

```bash
cd PIMSimulator

# ä½¿ç”¨ SCons æ„å»º
scons -j$(nproc)

# éªŒè¯æ„å»º
./build/pim_simulator --help

cd ..
```

### æ­¥éª¤ 4: æ„å»º XiangShan (å¯é€‰ï¼Œç”¨äºå®Œæ•´ç«¯åˆ°ç«¯æµ‹è¯•)

```bash
cd XiangShan

# ç”Ÿæˆ Verilog (å¯ç”¨ AHASD)
make verilog AHASD=1

# è¿™ä¼šç”Ÿæˆ build/XSTop.vï¼ŒåŒ…å« AHASD æ§åˆ¶æ¨¡å—

# æ„å»ºä»¿çœŸå™¨
make emu AHASD=1

cd ..
```

### æ­¥éª¤ 5: ä¸‹è½½æ¨¡å‹æƒé‡

```bash
# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p ONNXim/models/language_models

cd ONNXim/models/language_models

# ä¸‹è½½å¹¶è½¬æ¢æ¨¡å‹ (éœ€è¦å¤§é‡ç£ç›˜ç©ºé—´)
# OPT æ¨¡å‹
python3 ../../scripts/generate_transformer_onnx.py \
    --model facebook/opt-1.3b \
    --output opt-1.3b

python3 ../../scripts/generate_transformer_onnx.py \
    --model facebook/opt-6.7b \
    --output opt-6.7b

# LLaMA2 æ¨¡å‹
python3 ../../scripts/generate_transformer_onnx.py \
    --model meta-llama/Llama-2-7b-hf \
    --output llama2-7b

python3 ../../scripts/generate_transformer_onnx.py \
    --model meta-llama/Llama-2-13b-hf \
    --output llama2-13b

# PaLM æ¨¡å‹
python3 ../../scripts/generate_transformer_onnx.py \
    --model google/palm-8b \
    --output palm-8b

python3 ../../scripts/generate_transformer_onnx.py \
    --model google/palm-62b \
    --output palm-62b

cd ../../..
```

## ğŸ§ª è¿è¡Œå®éªŒ

### å¿«é€Ÿæµ‹è¯• (å•ä¸€é…ç½®)

éªŒè¯ç¯å¢ƒè®¾ç½®æ­£ç¡®ï¼š

```bash
# è¿è¡Œå•ä¸€é…ç½®çš„å¿«é€Ÿæµ‹è¯•
./scripts/run_single_config.py \
    --model llama2-7b:llama2-13b \
    --algorithm adaedl \
    --config ahasd_full \
    --output results/quick_test

# æ£€æŸ¥ç»“æœ
cat results/quick_test/metrics.txt
```

é¢„æœŸè¾“å‡ºåº”åŒ…å«ï¼š
- Throughput: ~40-50 tokens/sec
- Energy Efficiency: ~0.18-0.22 tokens/mJ
- Draft Acceptance Rate: ~70-80%
- EDC Prediction Accuracy: ~80-85%

### å®Œæ•´å®éªŒå¥—ä»¶

è¿è¡Œè®ºæ–‡ä¸­çš„æ‰€æœ‰å®éªŒï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export ONNXIM_HOME=$(pwd)/ONNXim
export PIM_SIM_HOME=$(pwd)/PIMSimulator

# è¿è¡Œå®Œæ•´å®éªŒ (å¯èƒ½éœ€è¦ 24-48 å°æ—¶)
./scripts/run_ahasd_simulation.sh

# ç»“æœå°†ä¿å­˜åœ¨ results/ahasd_YYYYMMDD_HHMMSS/
```

å®éªŒåŒ…æ‹¬ï¼š
- 3 ç§æ¨¡å‹é…ç½® (Small, Medium, Large)
- 4 ç§è‡ªé€‚åº”ç®—æ³• (SpecDec++, SVIP, AdaEDL, BanditSpec)
- 5 ç§ç³»ç»Ÿé…ç½® (æ¶ˆèå®éªŒ)
- **æ€»è®¡**: 60 ä¸ªå®éªŒé…ç½®

### å¹¶è¡Œè¿è¡Œå®éªŒ (åŠ é€Ÿ)

å¦‚æœæœ‰å¤šæ ¸ CPUï¼Œå¯ä»¥å¹¶è¡Œè¿è¡Œï¼š

```bash
# ä¿®æ”¹è„šæœ¬å¯ç”¨å¹¶è¡Œæ‰§è¡Œ
vim scripts/run_ahasd_simulation.sh
# å°† run_simulation å‡½æ•°è°ƒç”¨æ”¹ä¸ºåå°æ‰§è¡Œï¼š
# run_simulation ... &

# æˆ–è€…ä½¿ç”¨ GNU Parallel
parallel -j 8 ./scripts/run_single_config.py ::: \
    llama2-7b:llama2-13b \
    opt-1.3b:opt-6.7b \
    palm-8b:palm-62b
```

## ğŸ“Š ç»“æœåˆ†æ

### ç”Ÿæˆå›¾è¡¨

```bash
# åˆ†æç»“æœå¹¶ç”Ÿæˆè®ºæ–‡å›¾è¡¨
python3 scripts/analyze_ahasd_results.py results/ahasd_*/

# è¾“å‡º:
# - plots/throughput_comparison.png  (Figure 7a)
# - plots/energy_efficiency.png      (Figure 7b)
# - plots/ablation_study.png         (Figure 6)
# - plots/summary_table.csv          (Table 3)
```

### éªŒè¯ç¡¬ä»¶å¼€é”€

```bash
# éªŒè¯è®ºæ–‡ä¸­å£°ç§°çš„ç¡¬ä»¶å¼€é”€
python3 scripts/validate_hardware_costs.py

# åº”è¾“å‡º:
# EDC: 0.0002 mmÂ² âœ“
# TVC: 0.0002 mmÂ² âœ“
# AAU: 0.4500 mmÂ² âœ“
# Total: 0.4515 mmÂ² (2.51% of DRAM) âœ“
```

## ğŸ“ˆ é¢„æœŸç»“æœ

### ååé‡æå‡ (vs GPU-only baseline)

| æ¨¡å‹é…ç½® | SpecDec++ | SVIP | AdaEDL | BanditSpec |
|---------|-----------|------|--------|------------|
| OPT Small | 3.8Ã— | 4.1Ã— | 4.3Ã— | 4.6Ã— |
| LLaMA2 Medium | 3.2Ã— | 3.5Ã— | 3.8Ã— | 3.9Ã— |
| PaLM Large | 2.8Ã— | 3.1Ã— | 3.3Ã— | 3.5Ã— |

### èƒ½æ•ˆæå‡ (vs GPU-only baseline)

| æ¨¡å‹é…ç½® | SpecDec++ | SVIP | AdaEDL | BanditSpec |
|---------|-----------|------|--------|------------|
| OPT Small | 5.2Ã— | 5.6Ã— | 5.9Ã— | 6.1Ã— |
| LLaMA2 Medium | 4.5Ã— | 4.8Ã— | 5.1Ã— | 5.3Ã— |
| PaLM Large | 3.9Ã— | 4.2Ã— | 4.5Ã— | 4.7Ã— |

### æ¶ˆèå®éªŒ (LLaMA2-7B, AdaEDL)

| é…ç½® | ååé‡ | èƒ½æ•ˆ |
|-----|--------|------|
| Baseline (GPU-only) | 1.0Ã— | 1.0Ã— |
| NPU+PIM | 2.2Ã— | 1.9Ã— |
| +AAU | 2.7Ã— | 2.6Ã— |
| +EDC | 3.4Ã— | 4.5Ã— |
| +TVC (Full) | 3.8Ã— | 5.5Ã— |

**æ³¨æ„**: å®é™…ç»“æœå¯èƒ½æœ‰ Â±10% çš„å˜åŒ–ï¼Œè¿™æ˜¯ç”±äºï¼š
- æ¨¡å‹é‡åŒ–çš„éšæœºæ€§
- è‡ªé€‚åº”ç®—æ³•çš„éšæœºé‡‡æ ·
- æ¨¡æ‹Ÿå™¨çš„åˆå§‹åŒ–çŠ¶æ€

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: ONNXim ç¼–è¯‘å¤±è´¥

```bash
# æ£€æŸ¥ C++ ç¼–è¯‘å™¨ç‰ˆæœ¬
g++ --version  # åº”è¯¥æ˜¯ 10.0 æˆ–æ›´é«˜

# æ¸…ç†å¹¶é‡æ–°æ„å»º
cd ONNXim/build
rm -rf *
cmake .. -G Ninja -DCMAKE_BUILD_TYPE=Release -DENABLE_AHASD=ON
ninja -j$(nproc)
```

### é—®é¢˜ 2: æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# ä½¿ç”¨ä»£ç† (å¦‚æœåœ¨å›½å†…)
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
# è®¿é—® Hugging Face æ‰‹åŠ¨ä¸‹è½½åæ”¾ç½®åœ¨ ONNXim/models/language_models/
```

### é—®é¢˜ 3: æ¨¡æ‹Ÿå™¨è¿è¡Œç¼“æ…¢

```bash
# å¯ç”¨ä¼˜åŒ–
export ONNXIM_OPT_LEVEL=3
export OMP_NUM_THREADS=$(nproc)

# å‡å°‘æ—¥å¿—è¾“å‡º
./onnxim_main --log_level info  # è€Œä¸æ˜¯ debug æˆ– trace
```

### é—®é¢˜ 4: å†…å­˜ä¸è¶³

```bash
# å‡å°‘æ‰¹é‡å¤§å°
vim configs/ahasd_config_template.json
# å°† "batch_size": 1 æ”¹ä¸ºæ›´å°çš„å€¼

# æˆ–è€…å¢åŠ  swap
sudo fallocate -l 64G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

## ğŸ“ éªŒè¯æ¸…å•

è¿è¡Œå®Œå®éªŒåï¼ŒéªŒè¯ä»¥ä¸‹å†…å®¹ï¼š

- [ ] æ‰€æœ‰ 60 ä¸ªé…ç½®éƒ½æˆåŠŸå®Œæˆ
- [ ] æ¯ä¸ªé…ç½®ç›®å½•åŒ…å« `metrics.txt` å’Œ `results.json`
- [ ] ååé‡æå‡åœ¨é¢„æœŸèŒƒå›´å†… (2.8Ã—-4.6Ã—)
- [ ] èƒ½æ•ˆæå‡åœ¨é¢„æœŸèŒƒå›´å†… (3.9Ã—-6.1Ã—)
- [ ] ç¡¬ä»¶å¼€é”€éªŒè¯é€šè¿‡ (< 3% DRAM die)
- [ ] å›¾è¡¨ç”ŸæˆæˆåŠŸï¼Œä¸è®ºæ–‡å›¾è¡¨ç›¸ä¼¼

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥ `results/*/simulation.log` æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. è¿è¡Œè¯Šæ–­è„šæœ¬: `./scripts/test_e2e.sh`
3. æŸ¥çœ‹ FAQ: `docs/FAQ.md`
4. æäº¤ Issue: https://github.com/your-org/AHASD/issues

## ğŸ“„ å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬ä»£ç ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@inproceedings{ahasd2024,
  title={AHASD: Asynchronous Heterogeneous Architecture for LLM Speculative Decoding on Mobile Devices},
  author={Your Name et al.},
  booktitle={Conference Name},
  year={2024}
}
```

## ğŸ“… æ›´æ–°æ—¥å¿—

- **2024-11**: åˆå§‹å‘å¸ƒ
- **2024-11**: ä¿®å¤ mock æ•°æ®é—®é¢˜ï¼Œä½¿ç”¨çœŸå®æ¨¡æ‹Ÿå™¨
- **2024-11**: æ·»åŠ  XiangShan é›†æˆä»£ç 

